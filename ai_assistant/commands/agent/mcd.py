import json
from typing import Any

import typer
from openai import Client
from openai.types.responses import Response

from ai_assistant.commands import default_invoke_without_command
from ai_assistant.settings import OpenAISettings

helptext = """
åŸºäº OpenAI Responses API çš„ mcp-mcd å·¥å…·
"""

cmd = typer.Typer(help=helptext)


def add_default_invoke():
    for _cmd in (cmd,):
        _cmd.callback(invoke_without_command=True)(default_invoke_without_command)


add_default_invoke()


MCP_URL = "https://mcp.mcd.cn/mcp-servers/mcd-mcp"


class McdMcpOpenAIResponsesAgent:
    """OpenAI Responses API Agent å°è£…ç±»"""

    def __init__(
        self,
        base_url: str,
        api_key: str,
        model: str,
        mcp_token: str,
        mcp_url: str = MCP_URL,
        auto_approve: bool = True,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ– Agent

        Args:
            base_url: OpenAI API åŸºç¡€ URL
            api_key: OpenAI API Key
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            mcp_token: MCP æœåŠ¡çš„è®¤è¯ token
            mcp_url: MCP æœåŠ¡çš„ URL
            auto_approve: æ˜¯å¦è‡ªåŠ¨æ‰¹å‡†å·¥å…·è°ƒç”¨
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.client = Client(base_url=base_url, api_key=api_key)
        self.model = model
        self.mcp_token = mcp_token
        self.mcp_url = mcp_url
        self.auto_approve = auto_approve
        self.verbose = verbose

        # å®šä¹‰ MCP å·¥å…·é…ç½®
        self.tools = [
            {
                "type": "mcp",
                "server_label": "mcd",
                "server_description": "éº¦å½“åŠ³ MCP æœåŠ¡ï¼Œæä¾›ä¼˜æƒ åˆ¸æŸ¥è¯¢ã€æ´»åŠ¨æŸ¥è¯¢ç­‰åŠŸèƒ½",
                "server_url": self.mcp_url,
                "require_approval": "never" if auto_approve else "always",
                "headers": {
                    "Authorization": f"Bearer {self.mcp_token}",
                },
            }
        ]

    def _print_separator(self, title: str = "", char: str = "=", length: int = 60):
        """æ‰“å°åˆ†éš”çº¿"""
        if title:
            typer.echo(f"\n{char * length}")
            typer.echo(f"{title}")
            typer.echo(f"{char * length}")
        else:
            typer.echo(f"{char * length}")

    def _print_message(self, role: str, content: str):
        """æ‰“å°æ¶ˆæ¯"""
        if self.verbose:
            role_emoji = {"system": "ğŸ¤–", "user": "ğŸ‘¤", "assistant": "ğŸ¤–"}
            emoji = role_emoji.get(role, "ğŸ’¬")
            typer.echo(f"\n{emoji} [{role.upper()}]:")
            typer.echo(content)

    def _print_tool_call(self, tool_name: str, arguments: dict[str, Any]):
        """æ‰“å°å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        if self.verbose:
            typer.echo(f"\nğŸ”§ [å·¥å…·è°ƒç”¨] {tool_name}")
            typer.echo(f"å‚æ•°: {json.dumps(arguments, ensure_ascii=False, indent=2)}")

    def _print_response_info(self, response: Response):
        """æ‰“å°å“åº”ä¿¡æ¯"""
        if self.verbose:
            self._print_separator("å“åº”è¯¦æƒ…", "-", 60)
            typer.echo(f"Response ID: {response.id}")
            typer.echo(f"Model: {response.model}")
            typer.echo(f"Status: {response.status}")

            if hasattr(response, "usage") and response.usage:
                typer.echo("\nToken ä½¿ç”¨:")
                typer.echo(f"  - Input: {response.usage.input_tokens}")
                typer.echo(f"  - Output: {response.usage.output_tokens}")
                typer.echo(f"  - Total: {response.usage.total_tokens}")

    def run_conversation(self, user_query: str, system_prompt: str | None = None) -> str:
        """
        è¿è¡Œä¸€æ¬¡å®Œæ•´çš„å¯¹è¯æµç¨‹

        Args:
            user_query: ç”¨æˆ·çš„é—®é¢˜
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            åŠ©æ‰‹çš„æœ€ç»ˆå›å¤æ–‡æœ¬
        """
        # æ„å»ºåˆå§‹æ¶ˆæ¯
        messages: list[dict[str, str]] = []

        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
            self._print_message("system", system_prompt)

        messages.append({"role": "user", "content": user_query})
        self._print_message("user", user_query)

        # è°ƒç”¨ responses API
        self._print_separator("å¼€å§‹è°ƒç”¨ OpenAI Responses API")

        response = self.client.responses.create(
            model=self.model,
            tools=self.tools,  # type: ignore
            input=messages,  # type: ignore
        )

        # æ‰“å°å“åº”ä¿¡æ¯
        self._print_response_info(response)

        # æå–è¾“å‡ºæ–‡æœ¬
        output_text = response.output_text or ""

        if output_text:
            self._print_message("assistant", output_text)

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(response, "output") and response.output:
            for item in response.output:
                if item.type == "tool_use":
                    tool_name = item.name
                    tool_input = item.input if hasattr(item, "input") else {}
                    self._print_tool_call(tool_name, tool_input)

        return output_text

    def run_multi_turn_conversation(self, queries: list[str], system_prompt: str | None = None) -> list[str]:
        """
        è¿è¡Œå¤šè½®å¯¹è¯

        Args:
            queries: ç”¨æˆ·é—®é¢˜åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ¯è½®å¯¹è¯çš„åŠ©æ‰‹å›å¤åˆ—è¡¨
        """
        results = []

        for i, query in enumerate(queries, 1):
            self._print_separator(f"ç¬¬ {i}/{len(queries)} è½®å¯¹è¯", "=", 60)
            result = self.run_conversation(query, system_prompt if i == 1 else None)
            results.append(result)

        return results


@cmd.command()
def single(
    query: str = typer.Argument(..., help="ç”¨æˆ·é—®é¢˜ï¼Œä¾‹å¦‚ï¼šçœ‹ä¸€ä¸‹æˆ‘æœ‰å¤šå°‘å¼ ä¼˜æƒ åˆ¸"),
    mcp_token: str = typer.Option(..., help="MCD MCP æœåŠ¡çš„ Authorization token", envvar="MCD_MCP_TOKEN"),
    base_url: str | None = typer.Option(None, help="OpenAI API åŸºç¡€ URL", envvar="OPENAI_BASE_URL"),
    api_key: str | None = typer.Option(None, help="OpenAI API Key", envvar="OPENAI_API_KEY"),
    model: str | None = typer.Option(None, help="ä½¿ç”¨çš„æ¨¡å‹åç§°", envvar="OPENAI_MODEL"),
    auto_approve: bool = typer.Option(True, help="æ˜¯å¦è‡ªåŠ¨æ‰¹å‡†å·¥å…·è°ƒç”¨"),
    verbose: bool = typer.Option(True, help="æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯"),
):
    """è¿è¡Œå•æ¬¡å¯¹è¯æŸ¥è¯¢"""

    # åŠ è½½é…ç½®
    settings = OpenAISettings()
    base_url = base_url or settings.base_url
    api_key = api_key or settings.api_key
    model = model or settings.model

    # éªŒè¯å¿…éœ€å‚æ•°
    if not all([base_url, api_key, model, mcp_token]):
        typer.echo("âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€çš„é…ç½®å‚æ•°", err=True)
        typer.echo("è¯·é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æˆ–ç¯å¢ƒå˜é‡æä¾›ä»¥ä¸‹é…ç½®:", err=True)
        typer.echo("  - base_url (OPENAI_BASE_URL)", err=True)
        typer.echo("  - api_key (OPENAI_API_KEY)", err=True)
        typer.echo("  - model (OPENAI_MODEL)", err=True)
        typer.echo("  - mcp_token (MCD_MCP_TOKEN)", err=True)
        raise typer.Exit(code=1)

    # åˆ›å»º Agent
    agent = McdMcpOpenAIResponsesAgent(
        base_url=base_url,  # type: ignore
        api_key=api_key,  # type: ignore
        model=model,  # type: ignore
        mcp_token=mcp_token,
        auto_approve=auto_approve,
        verbose=verbose,
    )

    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢éº¦å½“åŠ³ç›¸å…³ä¿¡æ¯ã€‚
ä½ å¯ä»¥ä½¿ç”¨ MCP å·¥å…·æ¥è·å–ç”¨æˆ·çš„ä¼˜æƒ åˆ¸ä¿¡æ¯ã€å¯é¢†å–çš„ä¼˜æƒ åˆ¸ã€è¥é”€æ´»åŠ¨ç­‰ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶ä»¥å‹å¥½ã€æ¸…æ™°çš„æ–¹å¼å›ç­”ç”¨æˆ·ã€‚"""

    # è¿è¡Œå¯¹è¯
    try:
        result = agent.run_conversation(query, system_prompt)

        # è¾“å‡ºæœ€ç»ˆç»“æœ
        agent._print_separator("æœ€ç»ˆç»“æœ", "=", 60)
        typer.echo("\nâœ… æŸ¥è¯¢å®Œæˆ")
        typer.echo(f"\n{result}")

    except Exception as e:
        typer.echo(f"\nâŒ é”™è¯¯: {str(e)}", err=True)
        raise typer.Exit(code=1)


@cmd.command()
def quickstart(
    mcp_token: str = typer.Option(..., help="MCD MCP æœåŠ¡çš„ Authorization token", envvar="MCD_MCP_TOKEN"),
    base_url: str | None = typer.Option(None, help="OpenAI API åŸºç¡€ URL", envvar="OPENAI_BASE_URL"),
    api_key: str | None = typer.Option(None, help="OpenAI API Key", envvar="OPENAI_API_KEY"),
    model: str | None = typer.Option(None, help="ä½¿ç”¨çš„æ¨¡å‹åç§°", envvar="OPENAI_MODEL"),
    auto_approve: bool = typer.Option(True, help="æ˜¯å¦è‡ªåŠ¨æ‰¹å‡†å·¥å…·è°ƒç”¨"),
    verbose: bool = typer.Option(True, help="æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯"),
):
    """è¿è¡Œé¢„è®¾çš„æ¼”ç¤ºæŸ¥è¯¢ï¼ˆå¤šä¸ªåœºæ™¯ï¼‰"""

    # åŠ è½½é…ç½®
    settings = OpenAISettings()
    base_url = base_url or settings.base_url
    api_key = api_key or settings.api_key
    model = model or settings.model

    # éªŒè¯å¿…éœ€å‚æ•°
    if not all([base_url, api_key, model, mcp_token]):
        typer.echo("âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€çš„é…ç½®å‚æ•°", err=True)
        raise typer.Exit(code=1)

    # åˆ›å»º Agent
    agent = McdMcpOpenAIResponsesAgent(
        base_url=base_url,  # type: ignore
        api_key=api_key,  # type: ignore
        model=model,  # type: ignore
        mcp_token=mcp_token,
        auto_approve=auto_approve,
        verbose=verbose,
    )

    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢éº¦å½“åŠ³ç›¸å…³ä¿¡æ¯ã€‚
ä½ å¯ä»¥ä½¿ç”¨ MCP å·¥å…·æ¥è·å–ç”¨æˆ·çš„ä¼˜æƒ åˆ¸ä¿¡æ¯ã€å¯é¢†å–çš„ä¼˜æƒ åˆ¸ã€è¥é”€æ´»åŠ¨ç­‰ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶ä»¥å‹å¥½ã€æ¸…æ™°çš„æ–¹å¼å›ç­”ç”¨æˆ·ã€‚"""

    # é¢„è®¾çš„æ¼”ç¤ºæŸ¥è¯¢
    demo_queries = [
        "çœ‹ä¸€ä¸‹æˆ‘æœ‰å¤šå°‘å¼ ä¼˜æƒ åˆ¸",
        "ç°åœ¨æœ‰ä»€ä¹ˆä¼˜æƒ åˆ¸å¯ä»¥é¢†å–ï¼Ÿ",
        "æœ€è¿‘æœ‰ä»€ä¹ˆè¥é”€æ´»åŠ¨ï¼Ÿ",
        "å¸®æˆ‘é¢†å–ç›®å‰å¯é¢†å–çš„ä¼˜æƒ åˆ¸",
    ]

    # ç»Ÿè®¡ä¿¡æ¯
    success_count = 0
    fail_count = 0
    results = []

    # è¿è¡Œæ¼”ç¤º
    typer.echo("\n" + "=" * 60)
    typer.echo("ğŸš€ å¼€å§‹è¿è¡Œ OpenAI Responses API Agent Demo")
    typer.echo("=" * 60)

    for i, query in enumerate(demo_queries, 1):
        try:
            agent._print_separator(f"æ¼”ç¤º {i}/{len(demo_queries)}: {query}", "=", 60)
            result = agent.run_conversation(query, system_prompt if i == 1 else None)
            results.append({"query": query, "result": result, "success": True})
            success_count += 1
            typer.echo(f"\nâœ… æ¼”ç¤º {i} å®Œæˆ")
        except Exception as e:
            typer.echo(f"\nâŒ æ¼”ç¤º {i} å¤±è´¥: {str(e)}", err=True)
            results.append({"query": query, "result": str(e), "success": False})
            fail_count += 1

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    typer.echo("\n" + "=" * 60)
    typer.echo("ğŸ“Š æ¼”ç¤ºç»Ÿè®¡")
    typer.echo("=" * 60)
    typer.echo(f"æ€»è®¡: {len(demo_queries)} ä¸ªæŸ¥è¯¢")
    typer.echo(f"æˆåŠŸ: {success_count} ä¸ª")
    typer.echo(f"å¤±è´¥: {fail_count} ä¸ª")
    typer.echo(f"æˆåŠŸç‡: {success_count / len(demo_queries) * 100:.1f}%")

    # è¾“å‡ºè¯¦ç»†ç»“æœ
    typer.echo("\n" + "=" * 60)
    typer.echo("ğŸ“ è¯¦ç»†ç»“æœ")
    typer.echo("=" * 60)

    for i, item in enumerate(results, 1):
        status = "âœ…" if item["success"] else "âŒ"
        typer.echo(f"\n{status} æŸ¥è¯¢ {i}: {item['query']}")
        result = str(getattr(item, "result", ""))
        typer.echo(f"ç»“æœ: {result[:200]}...")  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦


@cmd.command()
def interactive(
    mcp_token: str = typer.Option(..., help="MCD MCP æœåŠ¡çš„ Authorization token", envvar="MCD_MCP_TOKEN"),
    base_url: str | None = typer.Option(None, help="OpenAI API åŸºç¡€ URL", envvar="OPENAI_BASE_URL"),
    api_key: str | None = typer.Option(None, help="OpenAI API Key", envvar="OPENAI_API_KEY"),
    model: str | None = typer.Option(None, help="ä½¿ç”¨çš„æ¨¡å‹åç§°", envvar="OPENAI_MODEL"),
    auto_approve: bool = typer.Option(True, help="æ˜¯å¦è‡ªåŠ¨æ‰¹å‡†å·¥å…·è°ƒç”¨"),
):
    """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""

    # åŠ è½½é…ç½®
    settings = OpenAISettings()
    base_url = base_url or settings.base_url
    api_key = api_key or settings.api_key
    model = model or settings.model

    # éªŒè¯å¿…éœ€å‚æ•°
    if not all([base_url, api_key, model, mcp_token]):
        typer.echo("âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€çš„é…ç½®å‚æ•°", err=True)
        raise typer.Exit(code=1)

    # åˆ›å»º Agent
    agent = McdMcpOpenAIResponsesAgent(
        base_url=base_url,  # type: ignore
        api_key=api_key,  # type: ignore
        model=model,  # type: ignore
        mcp_token=mcp_token,
        auto_approve=auto_approve,
        verbose=True,
    )

    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢éº¦å½“åŠ³ç›¸å…³ä¿¡æ¯ã€‚
    ä½ å¯ä»¥ä½¿ç”¨ MCP å·¥å…·æ¥è·å–ç”¨æˆ·çš„ä¼˜æƒ åˆ¸ä¿¡æ¯ã€å¯é¢†å–çš„ä¼˜æƒ åˆ¸ã€è¥é”€æ´»åŠ¨ç­‰ã€‚
    è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶ä»¥å‹å¥½ã€æ¸…æ™°çš„æ–¹å¼å›ç­”ç”¨æˆ·ã€‚
    """

    # æ¬¢è¿ä¿¡æ¯
    typer.echo("\n" + "=" * 60)
    typer.echo("ğŸ¤– OpenAI Responses API Agent - äº¤äº’å¼æ¨¡å¼")
    typer.echo("=" * 60)
    typer.echo("\nä½ å¯ä»¥é—®æˆ‘å…³äºéº¦å½“åŠ³çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼š")
    typer.echo("  - çœ‹ä¸€ä¸‹æˆ‘æœ‰å¤šå°‘å¼ ä¼˜æƒ åˆ¸")
    typer.echo("  - ç°åœ¨æœ‰ä»€ä¹ˆä¼˜æƒ åˆ¸å¯ä»¥é¢†å–ï¼Ÿ")
    typer.echo("  - æœ€è¿‘æœ‰ä»€ä¹ˆè¥é”€æ´»åŠ¨ï¼Ÿ")
    typer.echo("\nè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    typer.echo("=" * 60)

    # äº¤äº’å¾ªç¯
    is_first_query = True
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            query = typer.prompt("\nğŸ‘¤ ä½ ").strip()

            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if query.lower() in ["exit", "quit", "é€€å‡º", "q"]:
                typer.echo("\nğŸ‘‹ å†è§ï¼")
                break

            if not query:
                continue

            # è¿è¡Œå¯¹è¯
            agent.run_conversation(query, system_prompt if is_first_query else None)
            is_first_query = False

        except KeyboardInterrupt:
            typer.echo("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            typer.echo(f"\nâŒ é”™è¯¯: {str(e)}", err=True)


if __name__ == "__main__":
    cmd()
